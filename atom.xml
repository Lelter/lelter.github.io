<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lelter.github.io</id>
    <title>lelter&apos;s blog</title>
    <updated>2024-09-09T07:11:52.063Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lelter.github.io"/>
    <link rel="self" href="https://lelter.github.io/atom.xml"/>
    <logo>https://lelter.github.io/images/avatar.png</logo>
    <icon>https://lelter.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, lelter&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[信息熵和对比学习，为什么二分类任务中交叉熵和对比学习损失可以交换？]]></title>
        <id>https://lelter.github.io/post/xin-xi-shang-he-dui-bi-xue-xi-wei-shi-me-er-fen-lei-ren-wu-zhong-jiao-cha-shang-he-dui-bi-xue-xi-sun-shi-ke-yi-jiao-huan/</id>
        <link href="https://lelter.github.io/post/xin-xi-shang-he-dui-bi-xue-xi-wei-shi-me-er-fen-lei-ren-wu-zhong-jiao-cha-shang-he-dui-bi-xue-xi-sun-shi-ke-yi-jiao-huan/">
        </link>
        <updated>2024-09-09T06:55:20.000Z</updated>
        <content type="html"><![CDATA[<p>一个概率分布P的信息熵含量如下：</p>
<p>P(x)log(P(x))</p>
<p>KL散度基于信息熵，描述两个概率分布的差异：</p>
<figure data-type="image" tabindex="1"><img src="https://lelter.github.io/post-images/1725865006223.png" alt="" loading="lazy"></figure>
<p>交叉熵和KL散度关系密切：</p>
<figure data-type="image" tabindex="2"><img src="https://lelter.github.io/post-images/1725865060984.png" alt="" loading="lazy"></figure>
<p>也就是KL散度为P、Q的交叉熵减去P的信息熵。</p>
<p>而KL散度中P的信息熵固定，因此，优化KL散度和优化交叉熵是一样的，就是少一项。</p>
<h2 id="对比损失和交叉熵为什么可以交换">对比损失和交叉熵为什么可以交换</h2>
<p>交叉熵损失函数如下：</p>
<figure data-type="image" tabindex="3"><img src="https://lelter.github.io/post-images/1725865768853.png" alt="" loading="lazy"></figure>
<p>进行了softmax之后，公式为：</p>
<figure data-type="image" tabindex="4"><img src="https://lelter.github.io/post-images/1725865805828.png" alt="" loading="lazy"></figure>
<p>而infoNCE的损失函数为：</p>
<figure data-type="image" tabindex="5"><img src="https://lelter.github.io/post-images/1725865832245.png" alt="" loading="lazy"></figure>
<p>那么，可以将正样本看作标签为1的值，负样本为其他类别，进行交叉熵损失优化，效果一样。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[142. 环形链表 II]]></title>
        <id>https://lelter.github.io/post/142-huan-xing-lian-biao-ii/</id>
        <link href="https://lelter.github.io/post/142-huan-xing-lian-biao-ii/">
        </link>
        <updated>2024-09-08T08:09:32.000Z</updated>
        <content type="html"><![CDATA[<p>给定一个链表的头节点  head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。</p>
<p>如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。</p>
<p>不允许修改 链表。</p>
<p>示例 1：</p>
<p>输入：head = [3,2,0,-4], pos = 1<br>
输出：返回索引为 1 的链表节点<br>
解释：链表中有一个环，其尾部连接到第二个节点。<br>
示例 2：</p>
<p>输入：head = [1,2], pos = 0<br>
输出：返回索引为 0 的链表节点<br>
解释：链表中有一个环，其尾部连接到第一个节点。<br>
示例 3：</p>
<p>输入：head = [1], pos = -1<br>
输出：返回 null<br>
解释：链表中没有环。</p>
<p>提示：</p>
<p>链表中节点的数目范围在范围 [0, 104] 内<br>
-105 &lt;= Node.val &lt;= 105<br>
pos 的值为 -1 或者链表中的一个有效索引</p>
<p>进阶：你是否可以使用 O(1) 空间解决此题？</p>
<hr>
<p>1.哈希表，每次将节点存起来，如果表的数量大于1，说明遇到了重复的节点。</p>
<pre><code>table=collections.defaultdict(int)
        p=head
        while p:
            table[p]+=1
            if table[p]&gt;1:
                return p
            p=p.next
        return None
</code></pre>
<p>2.快慢指针<br>
f=2s,假设环外长度为a,环入口到相遇点距离为b,b到环入口距离为c，则相遇时，慢指针走了a+b，快指针走了a+n(b+c)+b，有a+(n+1)b+nc=2(a+b)，则a+b=n(b+c)，a=nb+nc-b=c+(n-1)(b+c)，从相遇点到环入口的距离为c，从头节点到环入口距离为a。因此，只需要让慢指针和头指针同时往后走，相遇时，就是环入口。</p>
<pre><code>        fast_p=slow_p=head
        while fast_p:
            fast_p=fast_p.next
            slow_p=slow_p.next
            if fast_p:
                fast_p=fast_p.next
            else:
                return None
            if fast_p==slow_p:
                fast_p=head
                while slow_p:
                    if slow_p==fast_p:
                        return slow_p
                    fast_p=fast_p.next
                    slow_p=slow_p.next
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[49. 字母异位词分组]]></title>
        <id>https://lelter.github.io/post/49-zi-mu-yi-wei-ci-fen-zu/</id>
        <link href="https://lelter.github.io/post/49-zi-mu-yi-wei-ci-fen-zu/">
        </link>
        <updated>2024-09-02T07:46:15.000Z</updated>
        <content type="html"><![CDATA[<p><strong>49. 字母异位词分组</strong></p>
<p>给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。</p>
<p>字母异位词 是由重新排列源单词的所有字母得到的一个新单词。<br>
示例 1:</p>
<p>输入: strs = [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;]<br>
输出: [[&quot;bat&quot;],[&quot;nat&quot;,&quot;tan&quot;],[&quot;ate&quot;,&quot;eat&quot;,&quot;tea&quot;]]<br>
示例 2:</p>
<p>输入: strs = [&quot;&quot;]<br>
输出: [[&quot;&quot;]]<br>
示例 3:</p>
<p>输入: strs = [&quot;a&quot;]<br>
输出: [[&quot;a&quot;]]</p>
<hr>
<h2>解法
<p>穷举法，时间复杂度为O(n^2)，超时了.</p>
<pre><code>class Solution:
    def wordIn(self, word1, word2):
        alphabel1=[0 for i in range(26)]
        alphabel2=[0 for i in range(26)]

        for i in word1:
            alphabel1[ord(i)-ord('a')]+=1
        for i in word2:
            alphabel2[ord(i)-ord('a')]+=1
        if alphabel1==alphabel2:
            return True
        else:
            return False
   

    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:
        visited = [0 for i in range(len(strs))]
        result = [[] for i in range(len(strs))]
        for i in range(len(strs)):
            if visited[i]:
                continue
            else:
                result[i].append(strs[i])
            for j in range(i + 1, len(strs)):
                visited[i] = 1

                if not visited[j]:
                    if self.wordIn(strs[i], strs[j]):
                        visited[j] = 1
                        result[i].append(strs[j])

                else:
                    continue
        result = [x for x in result if x != []]
        return result
</code></pre>
<p>python提供哈希表，也就是字典。<br>
collections.defaultdict(list)<br>
利用哈希表，key是一样的，因此就只需要添加值即可。</p>
<pre><code>    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:
        mp=collections.defaultdict(list)
        for st in strs:
            key=&quot;&quot;.join(sorted(st))
            mp[key].append(st)
        return list(mp.values())
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lora]]></title>
        <id>https://lelter.github.io/post/lora/</id>
        <link href="https://lelter.github.io/post/lora/">
        </link>
        <updated>2024-09-01T12:29:33.000Z</updated>
        <content type="html"><![CDATA[<h2 id="peft中用lora进行微调">PEFT中用Lora进行微调。</h2>
<figure data-type="image" tabindex="1"><img src="https://lelter.github.io/post-images/1725194054787.png" alt="" loading="lazy"></figure>
<h2 id="为什么lora中训练时间和显存没有明显降低">为什么Lora中训练时间和显存没有明显降低？</h2>
<p>仍需要计算主要模型的梯度，来优化Lora的参数。<br>
<img src="https://lelter.github.io/post-images/1725277440630.png" alt="" loading="lazy"><br>
因此，反向传播的时候，对B和A求梯度得到的公式需要对W进行求梯度，也就是整个模型的梯度。<img src="https://lelter.github.io/post-images/1725277498041.png" alt="" loading="lazy"><br>
但由于不用求和存取优化器的参数（像Adam优化器需要维护每个参数的一阶动量和二阶动量，分别是梯度的指数移动平均值和梯度平方的指数移动平均值），因此LoRA在显存方面就只是节省了主干模型的优化器状态。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[pytorch中交叉熵的问题]]></title>
        <id>https://lelter.github.io/post/pytorch-zhong-jiao-cha-shang-de-wen-ti/</id>
        <link href="https://lelter.github.io/post/pytorch-zhong-jiao-cha-shang-de-wen-ti/">
        </link>
        <updated>2024-08-30T06:19:30.000Z</updated>
        <content type="html"><![CDATA[<p><strong>F.cross_entropy()</strong> 是自带softmax的，因此不能在sigmoid之后直接送到该损失中。</p>
<p><strong>binary_cross_entropy_with_logits()</strong> 为logits值，未经过sigmoid转换。</p>
<p><strong>binary_cross_entropy()</strong> 和BCEloss需要输送的是概率值。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://lelter.github.io/post/hello-gridea/</id>
        <link href="https://lelter.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="https://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>